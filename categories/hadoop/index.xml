<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Hadoop on N3xtChen 的博客</title><link>https://n3xtchen.github.io/n3xtchen/categories/hadoop/</link><description>Recent content in Hadoop on N3xtChen 的博客</description><generator>Hugo -- gohugo.io</generator><language>zh-CN</language><copyright>© 2023 n3xtchen</copyright><lastBuildDate>Thu, 27 Feb 2014 00:00:00 +0000</lastBuildDate><atom:link href="https://n3xtchen.github.io/n3xtchen/categories/hadoop/index.xml" rel="self" type="application/rss+xml"/><item><title>Data Pig - 手动安装（Local 模式）</title><link>https://n3xtchen.github.io/n3xtchen/2014/02/27/hadoop---data-pig---installation/</link><pubDate>Thu, 27 Feb 2014 00:00:00 +0000</pubDate><guid>https://n3xtchen.github.io/n3xtchen/2014/02/27/hadoop---data-pig---installation/</guid><description>安装环境： # 软件列表： # Java-1.</description></item><item><title>Data Pig - Pig Latin 基础</title><link>https://n3xtchen.github.io/n3xtchen/2014/02/18/hadoop-data-pig-programming/</link><pubDate>Tue, 18 Feb 2014 00:00:00 +0000</pubDate><guid>https://n3xtchen.github.io/n3xtchen/2014/02/18/hadoop-data-pig-programming/</guid><description>通过三个章节的铺垫，现在开始深入了解 Pig 专属语言的 Pig Latin； 再次强调下， Pig Latin 是一门数据流语言（dataflow language）。</description></item><item><title>Hadoop 生态系统 - HCatalog</title><link>https://n3xtchen.github.io/n3xtchen/2014/02/17/hadoop-ecosystem---hcatalog/</link><pubDate>Mon, 17 Feb 2014 00:00:00 +0000</pubDate><guid>https://n3xtchen.github.io/n3xtchen/2014/02/17/hadoop-ecosystem---hcatalog/</guid><description>Apache HCatalog 是基于 Hadoop 之上的数据表和存储管理服务，让用户可以使用不同 的工具来（例如，Pig，MR 和 Hive）读写网格的数据。HCatalog 是以 HDFS 的数据关 系视图的形式来呈现给用户的，确保用户不需要关心数据的存储形式和存储方式。 HCatalog 可以以RCFile，文本文件或者制表符式的序列文件。它也提供 Rest 接口让 外部系统访问这些表的元数据。</description></item><item><title>Using Hadoop - 创建简单的 Oozie 工作流</title><link>https://n3xtchen.github.io/n3xtchen/2014/02/16/using-hadoop---oozie/</link><pubDate>Sun, 16 Feb 2014 00:00:00 +0000</pubDate><guid>https://n3xtchen.github.io/n3xtchen/2014/02/16/using-hadoop---oozie/</guid><description>来源： Oracle - Build Simple Workflows in Oozie</description></item><item><title>Hadoop 生态系统 - Ambari</title><link>https://n3xtchen.github.io/n3xtchen/2014/02/14/hadoop-ecosystem---ambari/</link><pubDate>Fri, 14 Feb 2014 00:00:00 +0000</pubDate><guid>https://n3xtchen.github.io/n3xtchen/2014/02/14/hadoop-ecosystem---ambari/</guid><description>Apache Ambari 提供了 Hadoop 集群的配置，管理和监控，100%的开源框架；它包括操作 工具的集合，以及强大的 API 接口来隐藏 Hadoop 的复杂度，简化集群操作。</description></item><item><title>Hadoop 生态系统 - falcon</title><link>https://n3xtchen.github.io/n3xtchen/2014/02/14/hadoop-ecosystem---falcon/</link><pubDate>Fri, 14 Feb 2014 00:00:00 +0000</pubDate><guid>https://n3xtchen.github.io/n3xtchen/2014/02/14/hadoop-ecosystem---falcon/</guid><description>Apache Falcon 是 Hadoop 的数据管理框架和管道处理框架。它能自动采集（ingest）， 管道（pipelines），灾难恢复和数据保留用例。用户可以依赖 Falcon 来取代复杂的 数据和管道处理的硬编码，它可以对这些函数复用最大，以及保证 Hadoop 的跨应用 之间的数据一致性。</description></item><item><title>Hadoop 生态系统 - Oozie</title><link>https://n3xtchen.github.io/n3xtchen/2014/02/14/hadoop-ecosystem---oozie/</link><pubDate>Fri, 14 Feb 2014 00:00:00 +0000</pubDate><guid>https://n3xtchen.github.io/n3xtchen/2014/02/14/hadoop-ecosystem---oozie/</guid><description>Apache Oozie 是一个用来调度 Hadoop 工作的 Java 网页应用。Ozzie 可以将多个工作 组装成一个工作逻辑单位。它被整合到 Hadoop 栈中，可以用来创建 MapReduce，Pig， Hive 和 Apache Sqoop 的工作。它还可以用来调度其他系统的工作，例如 Java 程序以 及 Shell 脚本。</description></item><item><title>Hadoop 生态系统 - ZooKeeper</title><link>https://n3xtchen.github.io/n3xtchen/2014/02/14/hadoop-ecosystem---zookeeper/</link><pubDate>Fri, 14 Feb 2014 00:00:00 +0000</pubDate><guid>https://n3xtchen.github.io/n3xtchen/2014/02/14/hadoop-ecosystem---zookeeper/</guid><description>Apache ZooKeeper 为 Hadoop 集群提供操作服务。它提供了一个分布配置服务，一个同步 服务和一个命名注册表。分布式程序是使用 ZooKeeper 存储和调节重要配置信息的更新。</description></item><item><title>Hadoop 生态系统 - Knox Gateway</title><link>https://n3xtchen.github.io/n3xtchen/2014/02/13/hadoop-ecosystem---knox-gateway/</link><pubDate>Thu, 13 Feb 2014 00:00:00 +0000</pubDate><guid>https://n3xtchen.github.io/n3xtchen/2014/02/13/hadoop-ecosystem---knox-gateway/</guid><description>Know Gateway（简称 knox）是为 Hadoop 集群提供单点验证和访问。这个项目的目的是 为访问集群数据数据和执行工作（jobs）的用户，和控制和管理集群的运营商简化了 Hadoop 安全。Knox 作为服务运行，并为整个 Hadoop 集群服务。</description></item><item><title>Data Pig - 数据类型和数据结构</title><link>https://n3xtchen.github.io/n3xtchen/2014/01/06/hadoop---data-pig---data-type/</link><pubDate>Mon, 06 Jan 2014 00:00:00 +0000</pubDate><guid>https://n3xtchen.github.io/n3xtchen/2014/01/06/hadoop---data-pig---data-type/</guid><description>Pig 数据类型主要分为两种类型：标量（Scalar）类型，它只包含单一的值；复合（Complex）类型，它可以包含多个值，可以是不同类型。</description></item><item><title>Data Pig - Pig 简介</title><link>https://n3xtchen.github.io/n3xtchen/2013/12/31/hadoop---data-pig/</link><pubDate>Tue, 31 Dec 2013 00:00:00 +0000</pubDate><guid>https://n3xtchen.github.io/n3xtchen/2013/12/31/hadoop---data-pig/</guid><description>什么是 Pig?</description></item></channel></rss>